{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Â TD6 - Understanding gradient descent for multilayer perceptron\n",
        "\n",
        "In the following notebook, we will cover error backpropagation and gradient descent in a multilayer perceptron **from scratch**.\n",
        "\n",
        "The task we will try to solve is quite easy: Given a 2-dimensional variable vector $\\mathbf{x} = (x_1, x_2)$, can be assign a binary class label (0 or 1) to each of the two vectors clusters?\n",
        "\n",
        "We will start with moon-shaped clusters, but feel free to try out other types of distributions (you can find some of them in `sklearn.datasets`.)"
      ],
      "metadata": {
        "id": "ClkHm8RjU-JT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QPkTYw5Vsdi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "from sklearn.datasets import make_moons, make_circles, make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X, y = make_circles(n_samples=1_000, factor=0.3, noise=0.05, random_state=0)\n",
        "X, y = make_moons(n_samples=1000, noise=0.05, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
        "\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "39Sy3OPxWToq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1af3506-e55a-478b-8e1b-8a6c82605a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2)\n",
            "(1000,)\n",
            "[1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 0 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0\n",
            " 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
            " 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1\n",
            " 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 0 1 1 1\n",
            " 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0\n",
            " 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 1 0\n",
            " 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0\n",
            " 0 1 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 1 0 1 0\n",
            " 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1\n",
            " 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 1\n",
            " 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0\n",
            " 0 1 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0\n",
            " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0\n",
            " 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1\n",
            " 0 1 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 1 0 1 0\n",
            " 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0\n",
            " 1 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1\n",
            " 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 0 1 1 1 0 1 1\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale data (standardization)\n",
        "train_mean = X_train.mean()\n",
        "train_std = X_train.std()\n",
        "\n",
        "print(train_mean)\n",
        "print(train_std)\n",
        "\n",
        "X_train = (X_train - train_mean) / train_std\n",
        "X_test = (X_test - train_mean) / train_std"
      ],
      "metadata": {
        "id": "zT-AjX7yIINw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70767630-a367-4f1b-8fb8-d271a635b546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.37964362633769544\n",
            "0.7131687903021432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, (train_ax, test_ax) = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(8, 4))\n",
        "\n",
        "train_ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
        "train_ax.set_ylabel(\"Feature #1\")\n",
        "train_ax.set_xlabel(\"Feature #0\")\n",
        "train_ax.set_title(\"Training data\")\n",
        "\n",
        "test_ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "test_ax.set_ylabel(\"Feature #1\")\n",
        "test_ax.set_xlabel(\"Feature #0\")\n",
        "_ = test_ax.set_title(\"Testing data\")"
      ],
      "metadata": {
        "id": "HlPPmSsEXtVX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "efa8c2de-3e4c-4c3c-bdf5-f586942bc466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear transform, a.k.a. one-layer of neurons a.k.a. perceptron (without activation function)\n",
        "\n",
        "First step on our journey is to define the simple operation of perceptron, without any activation function for now. We recall that a perceptron is doing:\n",
        "\n",
        "$$y^m = \\sum^n_i w^m_i x_i + b^m_i$$\n",
        "\n",
        "for every input data vector $\\mathrm{x}$ of dimension $n$, and for every neuron $m$. $y^m$ is the output of neuron $m$, $w^m$ are its synaptic weights (strenght of the connections between input and output), and $b^m$ are its bias weights.\n",
        "\n",
        "This can be written as a matrix-vector product:\n",
        "\n",
        "$$ \\mathrm{y} = \\mathrm{x} \\cdot \\mathrm{W} + \\mathrm{b}$$\n",
        "\n",
        "with $\\mathrm{x} = (x_1, x_2, \\dots x_n)$ and $\\mathrm{y} = (y_1, y_2, \\dots y_m)$. $\\mathrm{W}$ is a matrix of shape $(n \\times m)$ where $\\mathrm{W}_{(i, j)}$ is the weight between input $i$ and neuron $j$. Similarly, $\\mathrm{b} = (b_1, b_2 \\dots b_m)$ contains bias weights of all outputs neurons."
      ],
      "metadata": {
        "id": "orKAK9zUtRO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializer\n",
        "\n",
        "We define a first function to initialize some connections between neurons with random weights and biases:"
      ],
      "metadata": {
        "id": "aS1l5b0pyI3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_layer(input_shape, output_shape):\n",
        "    \"\"\"Create a layer of connections between neurons.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "        input_shape : int\n",
        "            Number of input neurons.\n",
        "        output_shape : int\n",
        "            Number of output neurons.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array of shape (input_shape, output_shape),\n",
        "        array of shape (output_shape, )\n",
        "            w and b, the weights and biases between neurons.\n",
        "    \"\"\"\n",
        "    # Create some uniformly distributed random weights using np.random.uniform\n",
        "    w = np.random.uniform(0.0,1.0,input_shape*output_shape)\n",
        "    b = np.random.uniform(0.0,1.0,input_shape*output_shape)\n",
        "    return w, b"
      ],
      "metadata": {
        "id": "SJ2Z0yXYtPqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b = create_layer(2, 3)\n",
        "assert w.shape == (2, 3)\n",
        "assert b.shape == (3, )"
      ],
      "metadata": {
        "id": "gSVtby-yXkAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "66eb48a7-c4c6-4c0e-fa6b-6692a6c785dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-01fdccee87cd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural net operator\n",
        "\n",
        "Then, we define a function that performs the neural network base operation defined above with some data, weights and biases:"
      ],
      "metadata": {
        "id": "Y6kh_pvyyRhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x, w, b):\n",
        "    \"\"\"A linear combination of inputs,\n",
        "    a.k.a a perceptron with linear activation:\n",
        "\n",
        "        y = x . w + b\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "        x : array of shape (n_samples, n)\n",
        "            Input data.\n",
        "        w : array of shape (n, m)\n",
        "            Weight matrix.\n",
        "        b : array of shape (m, )\n",
        "            Bias vector.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array of shape (n_samples, m)\n",
        "            y, the output of the linear transformation.\n",
        "    \"\"\"\n",
        "    #Â Using np.dot for \"dot product\" (scalar product)\n",
        "    return ..."
      ],
      "metadata": {
        "id": "AbY7pcaDyRAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[0.5, 0.5]]\n",
        "w = [[1.0], [1.0]]\n",
        "b = [1.0]\n",
        "y = linear(x, w, b)\n",
        "\n",
        "assert y[0, 0] == np.array([2.0])\n",
        "\n",
        "x = [[0.5, 0.5], [0.5, 0.5]]\n",
        "w = [[1.0, 1.0], [1.0, 1.0]]\n",
        "b = [1.0, 1.0]\n",
        "y = linear(x, w, b)\n",
        "\n",
        "assert y[0, 0] == 2.0\n",
        "assert y[0, 1] == 2.0\n",
        "assert y[1, 0] == 2.0\n",
        "assert y[1, 1] == 2.0"
      ],
      "metadata": {
        "id": "pERE3yLRBvFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Derivative\n",
        "\n",
        "Finally, because we will still need to compute gradients/derivatives of all operations in the neural network, we define its (very simple) derivative.\n",
        "\n",
        "Note that we allow to take the derivative **with regard to the parameters $\\mathrm{w}$ and $\\mathrm{b}$**, because we eventually want to know **what is the effect of changing these parameters on the activity of the network, to find the best parameters.**"
      ],
      "metadata": {
        "id": "w8-aqsKjyey2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_linear(x, w, b, with_regard_to=\"x\"):\n",
        "    \"\"\"Gradient of the activity of the linear perceptron\n",
        "    with regard to its parameters (weights and biases) or\n",
        "    input (x).\n",
        "\n",
        "    This is exactly like computing the derivative of an affine function,\n",
        "    but with regard to any of the term in the function:\n",
        "\n",
        "    y = x . w + b\n",
        "\n",
        "    ->\n",
        "        with regard to x:\n",
        "            dy/dx = w (everything is considered constant except x)\n",
        "\n",
        "        with regard to w:\n",
        "            dy/dw = x (everything is considered constant except w)\n",
        "\n",
        "        with regard to b:\n",
        "            dy/db = 1 (everything is considered constant except b)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        x : array of shape (n_samples, n)\n",
        "            Input data.\n",
        "        w : array of shape (n, m)\n",
        "            Weight matrix.\n",
        "        b : array of shape (m, )\n",
        "            Bias vector.\n",
        "        with_regard_to : \"w\", \"x\", \"b\"\n",
        "            Take derivative/gradient from parameters w\n",
        "            or b or from inputs x.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array of shape (m, n) or (n, n_samples) or (1, n_samples)\n",
        "            Derivative with regard to\n",
        "    \"\"\"\n",
        "    if with_regard_to == \"x\":\n",
        "        return w.T\n",
        "    elif with_regard_to == \"w\":\n",
        "        return x.T\n",
        "    elif with_regard_to == \"b\":\n",
        "        return np.ones((1, x.shape[0]))\n",
        "    else:\n",
        "        raise ValueError(\"'with_regard_to' must be equal to 'x', 'w' or 'b'.\")"
      ],
      "metadata": {
        "id": "KhezxrYHzHeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation functions\n",
        "\n",
        "Finally, we need to define activation functions and their derivatives. You may find the formula on internet.\n",
        "\n",
        "### Tanh"
      ],
      "metadata": {
        "id": "YvPcRGOfxXJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tanh(x):\n",
        "    \"\"\"Hyperbolic tangent activation function tanh(x).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        x : array\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array\n",
        "    \"\"\"\n",
        "    #Â Simply using np.tanh\n",
        "    return ...\n",
        "\n",
        "def d_tanh(x):\n",
        "    \"\"\"Hyperbolic tangent derivative tanh'(x).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        x : array\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array\n",
        "    \"\"\"\n",
        "    #Â Also using np.tanh\n",
        "    return ..."
      ],
      "metadata": {
        "id": "Vd_-ACSMoeRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 100)\n",
        "plt.plot(x, tanh(x))\n",
        "plt.plot(x, d_tanh(x))\n",
        "plt.axhline(0.0, linestyle=\"--\", alpha=0.5)\n",
        "plt.axvline(0.0, linestyle=\"--\", alpha=0.5)"
      ],
      "metadata": {
        "id": "Q0VnZO5Bog_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â Sigmoid"
      ],
      "metadata": {
        "id": "N1Oi0JPuo6z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"Sigmoid activation function Ï(x)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        x : array\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array\n",
        "    \"\"\"\n",
        "    #Â Using np.exp\n",
        "    return ...\n",
        "\n",
        "\n",
        "def d_sigmoid(x):\n",
        "    \"\"\"Sigmoid derivative function Ï'(x)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        x : array\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array\n",
        "    \"\"\"\n",
        "    # Using the previously defined sigmoid function\n",
        "    return ..."
      ],
      "metadata": {
        "id": "znsLyQVXoXki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 100)\n",
        "plt.plot(x, sigmoid(x))\n",
        "plt.plot(x, d_sigmoid(x))\n",
        "plt.axhline(0.0, linestyle=\"--\", alpha=0.5)\n",
        "plt.axvline(0.0, linestyle=\"--\", alpha=0.5)"
      ],
      "metadata": {
        "id": "rvVNSKFgqArd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss functions\n",
        "\n",
        "Given a prediction $\\hat{y}$ (`y_pred` in the code) and a true value $y$ (`y_true` in the code), give **a measure of the distance or likelihood of the obtained prediction with regard to what we were expecting**.\n",
        "\n",
        "We will cover two main loss functions, for regression and classification."
      ],
      "metadata": {
        "id": "ReQB97aRaCOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression: Mean Squared Error\n",
        "\n",
        "$$MSE(y,\\hat{y}) = \\frac{1}{2N} \\sum^N_i(\\hat{y}_i - y_i)^2$$\n",
        "\n",
        "This is basically **the mean distance between $\\hat{y}$ and $y$** (but squared, and divided by two for convenience when computing its derivative.)\n",
        "\n",
        "$\\rightarrow$ The shorter the distance, the better the fit."
      ],
      "metadata": {
        "id": "CDv0F0fBbdsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    \"\"\"Mean Squared Error.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        y_true : array of shape (n_samples, )\n",
        "            Expected response of the model.\n",
        "        y_pred : array of shape (n_samples, )\n",
        "            Actual response of the model.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array of shape (1, )\n",
        "            MSE (square distance) of expected versus actual response.\n",
        "    \"\"\"\n",
        "    #Â Using np.mean and '**2' to perform 'power(array, 2)'\n",
        "    return ..."
      ],
      "metadata": {
        "id": "5MTpT7V9qwxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification: Cross-entropy\n",
        "\n",
        "Also called **negative log-likelihood** or **logistic loss** when performing binary classification.\n",
        "\n",
        "In the binary case (only two classes):\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\hat{y}, y) = - \\frac{1}{N} \\sum^N_i y_i \\times \\ln(\\hat{y_i}) + (1 - y_i) \\times \\ln(1 - \\hat{y_i})\n",
        "$$\n",
        "\n",
        "As we are estimating probabilities when doing classification (probability of being a cat or a dog, for instance), error can be computed as a **likelihood measure between probabilities distributions**.\n",
        "\n",
        "Basically, we measure how good our model is at responding that:\n",
        "- a cat is a cat, $y \\times \\ln(\\hat{y})$, or how good is our estimation of $p$ in a binomial distribution of cats and not cats\n",
        "- a dog is not a cat, $(1 - y) \\times \\ln(1 - \\hat{y})$, or how good is our estimation of $1-p$ in a binomial distribution of cats and not cats.\n",
        "\n",
        "$\\rightarrow$ If the model is good at both, then **cross-entropy will reach 0**."
      ],
      "metadata": {
        "id": "_MtZRFRtcTLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_crossentropy(y_true, y_pred):\n",
        "    \"\"\"Binary cross-entropy.\n",
        "\n",
        "    Also known as negative log-likelihood or logistic loss.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        y_true : array of shape (n_samples, )\n",
        "            Expected response of the model.\n",
        "        y_pred : array of shape (n_samples, )\n",
        "            Actual response of the model.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        array of shape (1, )\n",
        "            MSE (square distance) of expected versus actual response.\n",
        "    \"\"\"\n",
        "    # Using np.log and np.mean (do not forget the leading minus sign !)\n",
        "    return ..."
      ],
      "metadata": {
        "id": "PrAsHXTOcT2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: general case with $C$ classes\n",
        "\n",
        "In the general case with $C$ different classes (not only two):\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\hat{y}, y) = - \\frac{1}{N} \\sum^N_i \\sum_c^C y_i^c \\times \\ln(\\hat{y_i^c})\n",
        "$$\n",
        "\n",
        "We will not cover this case for now, as our problem involves only two classes.\n",
        "You can implement it as a bonus question."
      ],
      "metadata": {
        "id": "uGe1pYEcgY4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crossentropy(y_true, y_pred):\n",
        "    ..."
      ],
      "metadata": {
        "id": "9XdZWWvAgCbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Derivatives\n",
        "\n",
        "Finally, we need loss functions derivatives to perform gradient descent:"
      ],
      "metadata": {
        "id": "ql5u4RZMg-Wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_mse(y_true, y_pred):\n",
        "    return  y_pred - y_true\n",
        "\n",
        "def d_binary_crossentropy(y_true, y_pred):\n",
        "    return np.divide(y_pred - y_true, y_pred * (1 - y_pred))\n",
        "\n",
        "def d_crossentropy(y_true, y_pred):\n",
        "    ..."
      ],
      "metadata": {
        "id": "l-JKTxung9Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â Visualizing the objective\n",
        "\n",
        "The loss function chosen to evaluate our problem will define **the objective of our optimization process.** In other words, the loss will measure how well our model is predicting the data, and how much we should change model's parameters to make better prediction.\n",
        "\n",
        "Machine learning techniques thus always aim at the same objective: **to find  parameters that make the loss (or error) as minimal as possible:**\n",
        "\n",
        "$$ \\underset{\\theta}{\\mathrm{argmin}}~~\\mathcal{L}(\\hat{y}=f(\\theta, x), y) $$\n",
        "\n",
        "with $f(\\theta, x)$ as the result of our neural network, and parameters $\\theta = \\{\\mathbf{w}, \\mathbf{b}\\}$ as all weights and biases in the network.\n",
        "\n",
        "Given a simple one layer neural network (a perceptron) with bias $\\mathrm{b} = 0$, with only two weights $w_1, w_2$, and with sigmoid activation function, let's have a look at what this loss function looks like in our case."
      ],
      "metadata": {
        "id": "FFlrqZjrqtMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_surface(loss_values, w1, w2, view_init, loss_name, ax):\n",
        "\n",
        "    min_index = np.unravel_index(np.argmin(loss_values), loss_values.shape)\n",
        "    min_loss = loss_values[min_index]\n",
        "    min_w1, min_w2 = w1[min_index[1]], w2[min_index[0]]\n",
        "\n",
        "    ax.scatter(\n",
        "        min_w1,\n",
        "        min_w2,\n",
        "        min_loss,\n",
        "        c=\"red\",\n",
        "        s=100,\n",
        "        label=f\"Min. = {min_loss:.3f}\"\n",
        "        )\n",
        "\n",
        "    ax.plot_surface(\n",
        "        *np.meshgrid(w1, w2),\n",
        "        loss_values,\n",
        "        cmap=\"RdYlGn_r\",\n",
        "        alpha=0.5\n",
        "        )\n",
        "\n",
        "    ax.set_xlabel(\"$W_1$\", size=20)\n",
        "    ax.set_ylabel(\"$W_2$\", size=20)\n",
        "    ax.set_zlabel(loss_name, size=20, rotation=\"vertical\")\n",
        "\n",
        "    ax.view_init(*view_init)\n",
        "\n",
        "    ax.legend()\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def plot_nonlinear_loss_landscape(x, y, param_range, steps):\n",
        "\n",
        "    w1 = np.linspace(*param_range, steps)\n",
        "    w2 = np.linspace(*param_range, steps)\n",
        "\n",
        "    mse_values = np.zeros((steps, steps))\n",
        "    crossentropy_values = np.zeros((steps, steps))\n",
        "    for i in range(steps):\n",
        "        for j in range(steps):\n",
        "\n",
        "            w = np.array([[w1[i]], [w2[j]]])\n",
        "\n",
        "            h = linear(x, w, 0)\n",
        "            y_pred = sigmoid(h)\n",
        "\n",
        "            mse_values[i, j] = mse(y, y_pred)\n",
        "            crossentropy_values[i, j] = binary_crossentropy(y, y_pred)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15), subplot_kw={\"projection\": \"3d\"})\n",
        "\n",
        "    plot_surface(mse_values, w1, w2, (30, 100), \"MSE\", ax1)\n",
        "    plot_surface(crossentropy_values, w1, w2, (30, 100), \"Bin. Crossentropy\", ax2)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Q-ZPXaM5sPhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_nonlinear_loss_landscape(X_train, y_train, (-10, 10), 100)"
      ],
      "metadata": {
        "id": "6v5EfevdJ9Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you noticed, this code is a bit long to execute. This is because we computed the loss value of our simple neural network **for 10,000 different combinations of parameter $w_1$ and $w_2$**, as shown on the plot.\n",
        "\n",
        "This plot is of course impossible to build for real world applications: If there was more than 2 parameters in the model, this plot would have more than 4 dimensions. It would also take a very long time to create, as it requires to test all combinations of parameters.\n",
        "\n",
        "This is why we use methods such as gradient descent to find the best values of parameters."
      ],
      "metadata": {
        "id": "5zujaRiQy_UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â Question: given these plots, what is the most appropriate loss function to use for our problem and why? What are the best parameters?"
      ],
      "metadata": {
        "id": "tWD1h_gI012j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lrlBfEfE1H1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First model: One layer neural network with sigmoid activation\n",
        "\n",
        "The network is defined by two successive operations:\n",
        "\n",
        "$$\\mathbf{z} = \\mathbf{x} \\cdot \\mathbf{W} + \\mathbf{b}$$\n",
        "$$\\mathbf{y} = sigmoid(\\mathbf{z})$$\n",
        "\n",
        "All parameters are randomly initialized.\n",
        "\n",
        "We will use cross-entropy as a loss function for this classification task.\n",
        "The network will learn through gradient descent.\n",
        "\n",
        "The algorithm can be cut in three main parts:\n",
        "\n",
        "1. Make a prediction with current parameters $\\mathbf{w, b}$. This is also called **the forward pass**, because information (the data here) goes from input of the model to its output.\n",
        "\n",
        "$$\\mathbf{z} = \\mathbf{x} \\cdot \\mathbf{W} + \\mathbf{b}$$\n",
        "$$\\mathbf{y} = sigmoid(\\mathbf{z})$$\n",
        "\n",
        "2. Compute error (loss) and compute the loss gradient with regard to all parameters of the model. This is also called **the backward pass**, because information (the error here) goes from output of the model to its input. It will inform us about the slope around the current parameters in the loss landscape (where is it going down and how fast ?)\n",
        "\n",
        "$$\\nabla_\\mathbf{w} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{w}}$$\n",
        "\n",
        "$$\\nabla_\\mathbf{b} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z}} \\cdot \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{b}}$$\n",
        "\n",
        "3. Update parameters $\\mathbf{w, b}$ using the gradient. This is called **gradient descent**. The parameter $\\eta$ is called the learning rate, and controls how fast we jump from one position to another on the loss landscape, going down the slope (the gradient).\n",
        "\n",
        "$$\\mathbf{w} := \\mathbf{w}-\\eta \\times \\nabla_\\mathbf{w} (\\mathcal{L})$$\n",
        "$$\\mathbf{b} := \\mathbf{b}-\\eta \\times \\nabla_\\mathbf{b} (\\mathcal{L})$$\n",
        "\n",
        "\n",
        "Doing so, we will slowly slide down the loss landscape we could see on the previous figures, until we reach a position close to the minimum point."
      ],
      "metadata": {
        "id": "oDaN7PAq1Fw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1]  # X dimensions (here, 2)\n",
        "output_shape = 1  # one neuron output\n",
        "\n",
        "loss_values = []\n",
        "y_preds = []\n",
        "all_grad_w = []\n",
        "\n",
        "all_w = []\n",
        "all_b = []\n",
        "\n",
        "\n",
        "#--- PARAMETERS and HYPERPARAMETERS ---\n",
        "\n",
        "# some random weights to start with\n",
        "w, b = create_layer(input_shape, output_shape)\n",
        "\n",
        "#Â You can also try using some extreme values\n",
        "# w = np.array([[-10], [10]])\n",
        "# b = np.array([0])\n",
        "\n",
        "\n",
        "# Number of epochs (iterations of gradient descent)\n",
        "n_epochs = 100\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.001\n",
        "\n",
        "#--- TRAINING LOOP ---\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    #--- PREDICTION (FORWARD PASS) ---\n",
        "\n",
        "    #--- Layer 0: X_train ---\n",
        "    # Nothing to do here, X_train virtually enters the network.\n",
        "\n",
        "\n",
        "    #--- Layer 1 (input to output layer) ---\n",
        "    # z = w . x + b\n",
        "    z = ...\n",
        "    # y = sigmoid(z)\n",
        "    y = ...\n",
        "\n",
        "    #--- Loss: L(y_true, y) ---\n",
        "    loss = binary_crossentropy(y_train, y)\n",
        "\n",
        "    y_preds.append(y)\n",
        "\n",
        "    # Record everything before updating\n",
        "    loss_values.append(loss)\n",
        "    all_w.append(w)\n",
        "    all_b.append(b)\n",
        "\n",
        "\n",
        "    #--- BACK PROPAGATION (BACKWARD PASS) ---\n",
        "\n",
        "    # All gradients and derivatives are marked\n",
        "    # with \"df/dx\" notation.\n",
        "    # Note that this is not rigorous for gradients\n",
        "    # however.\n",
        "\n",
        "    # dL/dy\n",
        "    dL_dy = d_binary_crossentropy(y_train, y)\n",
        "\n",
        "    # dL/dz = dL/dy * dy/dz\n",
        "    dL_dz = ...\n",
        "\n",
        "    # \"dL/dw\" (grad L/w) = grad z/w . dL/dz\n",
        "    grad_z_w = d_linear(X_train, w, b, with_regard_to=\"w\")\n",
        "    grad_L_w = ...\n",
        "\n",
        "    # \"dL/db\" (grad L/b) = grad z/b . dL/dz\n",
        "    grad_z_b = d_linear(X_train, w, b, with_regard_to=\"b\")\n",
        "    grad_L_b = ...\n",
        "\n",
        "    ##--- GRADIENT DESCENT ---\n",
        "\n",
        "    w = w - ...\n",
        "    b = b - ...\n",
        "\n",
        "    all_grad_w.append(grad_L_w)"
      ],
      "metadata": {
        "id": "zeWb5eZFF57u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_values)\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "metadata": {
        "id": "t_1K1QKw6BXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1_values = np.linspace(-10, 10, 100)\n",
        "w2_values = np.linspace(-10, 10, 100)\n",
        "\n",
        "crossentropy_values = np.zeros((100, 100))\n",
        "for i in range(100):\n",
        "    for j in range(100):\n",
        "\n",
        "        w = np.array([[w1_values[i]], [w2_values[j]]])\n",
        "\n",
        "        h = linear(X_train, w, all_b[-1])\n",
        "        y_pred = sigmoid(h)\n",
        "\n",
        "        crossentropy_values[j, i] = binary_crossentropy(y_train, y_pred)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
        "\n",
        "plot_surface(crossentropy_values, w1_values, w2_values, (30, 30), \"Bin. Crossentropy\", ax1)\n",
        "\n",
        "w1s = [ws[0] for ws in all_w]\n",
        "w2s = [ws[1] for ws in all_w]\n",
        "\n",
        "ax1.scatter(w1s, w2s, loss_values)\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "grad_w1s = np.array([grad[0] for grad in all_grad_w])\n",
        "grad_w2s = np.array([grad[1] for grad in all_grad_w])\n",
        "\n",
        "ax2.contourf(*np.meshgrid(w1_values, w2_values), crossentropy_values, cmap=\"RdYlGn_r\", levels=50, alpha=0.5)\n",
        "quiver = ax2.quiver(w1s, w2s, -grad_w1s*lr, -grad_w2s*lr, scale=20)\n",
        "\n",
        "ax2.set_title(\"Gradient update value ($-\\\\eta \\\\times \\\\nabla_{\\\\mathbf{w}}(\\\\mathcal{L})$)\", size=20)\n",
        "ax2.set_ylabel(\"$W_2$\", size=20)\n",
        "ax2.set_xlabel(\"$W_1$\", size=20)"
      ],
      "metadata": {
        "id": "9Yzr1O4JAHUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.linspace(-2.5, 2.5, 100)\n",
        "x2 = np.linspace(-1.5, 1.5, 100)\n",
        "\n",
        "X_grid = np.meshgrid(x1, x2)\n",
        "X_grid = np.concatenate([X_grid[0].reshape(-1, 1), X_grid[1].reshape(-1, 1)], axis=1)\n",
        "\n",
        "y = sigmoid(linear(X_grid, w, b))\n",
        "\n",
        "y_pred = y.reshape(100, 100)\n",
        "\n",
        "plt.contourf(*np.meshgrid(x1, x2), y_pred, cmap=\"coolwarm\")\n",
        "plt.colorbar(label=\"Sigmoid activation value\")\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "plt.xlabel(\"Feature #0\")\n",
        "plt.ylabel(\"Feature #1\")\n",
        "plt.title(\"Output neuron activation for all data plane\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cYvRhc9I5ZhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred, y_test, threshold=0.5):\n",
        "    \"\"\"Classification accuracy, with decision threshold.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        y_pred : array\n",
        "            Predictions (between 0 and 1)\n",
        "        y_test : array\n",
        "            Ground truth class values (0 or 1)\n",
        "        threshold : float\n",
        "            A threshold between 0 and 1. Predictions above the\n",
        "            threshold will be interpreted as class 1, 0 otherwise.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "        float\n",
        "            Accuracy score.\n",
        "    \"\"\"\n",
        "    y = y_pred.copy().squeeze()\n",
        "    y[y > 0.5] = 1.0\n",
        "    y[y <= 0.5] = 0.0\n",
        "    return np.mean(y == y_test)"
      ],
      "metadata": {
        "id": "kkExCd3ndhiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply model with w and b parameters on test data\n",
        "y_pred = ...\n",
        "print(f\"Accuracy: {accuracy(y_pred, y_test, threshold=0.5) * 100}%\")"
      ],
      "metadata": {
        "id": "CXJO9zHodsnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question: conclude on the model's performance, and comment the plots.\n",
        "\n",
        "### Question (bonus): change the training loop to perform mini batch stochastic gradient descent.\n",
        "\n",
        "That means gradient is computed only on small \"batches\" (pieces) of data at a time. Dataset is randomly cut into small pieces at the begining of every epochs, and gradient descent is performed on every pieces (batches) of data during the epoch.\n",
        "\n",
        "This adds a for-loop in the algorithm above:\n",
        "\n",
        "```python\n",
        "batch_size = 100 #Â max number of samples in a batch, for instance, 100\n",
        "\n",
        "for epoch in epochs:\n",
        "\n",
        "    batches = ... # randomly cut the dataset in batches of size batch_size\n",
        "\n",
        "    for batch in batches:\n",
        "\n",
        "        # forward, loss, backward and gradient descent on each batch.\n",
        "```"
      ],
      "metadata": {
        "id": "Cy5mc8WWaJhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second model: Multilayer perceptron (2 layers)\n",
        "\n",
        "The network is now defined by four successive operations:\n",
        "\n",
        "- Layer 1 (input to hidden layer):\n",
        "$$\\mathbf{z_1} = \\mathbf{x} \\cdot \\mathbf{W_1} + \\mathbf{b_1}$$\n",
        "$$\\mathbf{h} = \\tanh(\\mathbf{z_1})$$\n",
        "\n",
        "- Layer 2 (hidden to output layer):\n",
        "$$\\mathbf{z_2} = \\mathbf{h} \\cdot \\mathbf{W_2} + \\mathbf{b_2}$$\n",
        "$$\\mathbf{y} = sigmoid(\\mathbf{z_2})$$\n",
        "\n",
        "As before, all parameters ($\\mathbf{W_1},  \\mathbf{b_1}, \\mathbf{W_2}, \\mathbf{b_2}$) are randomly initialized.\n",
        "\n",
        "Gradient descent algorithm can be applied using the same equations as above, but with two more derivation steps:\n",
        "\n",
        "- Gradient with regard to parameters of layer 2 (same as before):\n",
        "\n",
        "$$\\nabla_\\mathbf{w_2} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z_2}} \\cdot \\frac{\\partial \\mathbf{z_2}}{\\partial \\mathbf{w_2}}$$\n",
        "\n",
        "$$\\nabla_\\mathbf{b_2} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z_2}} \\cdot \\frac{\\partial \\mathbf{z_2}}{\\partial \\mathbf{b_2}}$$\n",
        "\n",
        "- Gradient with regard to parameters of layer 1 (going one layer deeper than above):\n",
        "\n",
        "$$\\nabla_\\mathbf{w_1} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z_2}} \\cdot \\frac{\\partial \\mathbf{z_2}}{\\partial \\mathbf{h}} \\times \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z_1}} \\cdot \\frac{\\partial \\mathbf{z_1}}{\\partial \\mathbf{w_1}} $$\n",
        "\n",
        "$$\\nabla_\\mathbf{b_1} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\times \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z_2}} \\cdot \\frac{\\partial \\mathbf{z_2}}{\\partial \\mathbf{h}} \\times \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{z_1}} \\cdot \\frac{\\partial \\mathbf{z_1}}{\\partial \\mathbf{b_1}} $$"
      ],
      "metadata": {
        "id": "O0y3FEY65jv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1]  # X dimensions (here, 2)\n",
        "output_shape = 1  # one neuron output\n",
        "\n",
        "loss_values = []\n",
        "y_preds = []\n",
        "\n",
        "#--- PARAMETERS and HYPERPARAMETERS ---\n",
        "\n",
        "hidden_neurons = 3  # 3 hidden neurons\n",
        "\n",
        "# some random weights to start with\n",
        "w1, b1 = create_layer(input_shape, hidden_neurons)\n",
        "w2, b2 = create_layer(hidden_neurons, output_shape)\n",
        "\n",
        "# Number of epochs (iterations of gradient descent)\n",
        "n_epochs = 500\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "   #--- PREDICTION (FORWARD PASS) ---\n",
        "\n",
        "    #--- Layer 0: X_train ---\n",
        "    # Nothing to do here, X_train virtually enters the network.\n",
        "\n",
        "    #--- Layer 1 (input to hidden layer) ---\n",
        "    # z1 = w1 . x + b1\n",
        "    z1 = ...\n",
        "    # h = tanh(z1)\n",
        "    h = ...\n",
        "\n",
        "    #--- Layer 2 (hidden to output layer) ---\n",
        "    # z2 = w2 . h + b2\n",
        "    z2 = ...\n",
        "    # y = sigmoid(z2)\n",
        "    y = ...\n",
        "\n",
        "    #--- Loss: L(y_true, y) ---\n",
        "    loss = binary_crossentropy(y_train, y)\n",
        "\n",
        "    y_preds.append(y)\n",
        "\n",
        "    # Record loss before updating\n",
        "    loss_values.append(loss)\n",
        "\n",
        "    #--- BACK PROPAGATION (BACKWARD PASS) ---\n",
        "\n",
        "    # All gradients and derivatives are marked\n",
        "    # with \"df/dx\" notation.\n",
        "    # Note that this is not rigorous for gradients\n",
        "    # however.\n",
        "\n",
        "    #--- Loss ---\n",
        "\n",
        "    # dL/dy\n",
        "    dL_dy = d_binary_crossentropy(y_train, y)\n",
        "\n",
        "    #--- Layer 2 ---\n",
        "\n",
        "    # dL/dz2 = dL/dy * dy/dz2\n",
        "    dL_dz2 = ...\n",
        "\n",
        "    # \"dL/dw2\" (grad L/w2) = grad z2/w2 . dL/dz2\n",
        "    grad_z2_w2 = ...\n",
        "    grad_L_w2 = ...\n",
        "\n",
        "    # \"dL/db2\" (grad L/b2) = grad z2/b2 . dL/dz2\n",
        "    grad_z2_b2 = ...\n",
        "    grad_L_b2 = ...\n",
        "\n",
        "    #--- Layer 1 ---\n",
        "\n",
        "    # dL/dh = dL/dz2 . dz2/dh\n",
        "    dz2_dh = ...\n",
        "    dL_dh = ...\n",
        "\n",
        "    # dL/dz1 = dL/dh * dh/dz1\n",
        "    dL_dz1 = ...\n",
        "\n",
        "    # \"dL/dw1\" (grad L/w1) = grad z1/w1 . dL/dz1\n",
        "    grad_z1_w1 = ...\n",
        "    grad_L_w1 = ...\n",
        "\n",
        "    # \"dL/db1\" (grad L/b1) = grad z1/b1 . dL/dz1\n",
        "    grad_z1_b1 = ...\n",
        "    grad_L_b1 = ...\n",
        "\n",
        "\n",
        "    ##--- GRADIENT DESCENT ---\n",
        "\n",
        "    ..."
      ],
      "metadata": {
        "id": "WP4KloL27lEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_values)\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "metadata": {
        "id": "vfRrPWF8_Ld8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.linspace(-2.5, 2.5, 100)\n",
        "x2 = np.linspace(-1.5, 1.5, 100)\n",
        "\n",
        "X_grid = np.meshgrid(x1, x2)\n",
        "X_grid = np.concatenate([X_grid[0].reshape(-1, 1), X_grid[1].reshape(-1, 1)], axis=1)\n",
        "\n",
        "h = tanh(linear(X_grid, w1, b1))\n",
        "y_pred = sigmoid(linear(h, w2, b2))\n",
        "\n",
        "y_pred = y_pred.reshape(100, 100)\n",
        "\n",
        "plt.contourf(*np.meshgrid(x1, x2), y_pred, cmap=\"coolwarm\")\n",
        "plt.colorbar(label=\"Sigmoid activation value\")\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "plt.xlabel(\"Feature #0\")\n",
        "plt.ylabel(\"Feature #1\")\n",
        "plt.title(\"Output neuron activation for all data plane\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_UN8ypVn1vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply model with w1, b1, w2 and b2 parameters on test data\n",
        "y_pred = ...\n",
        "print(f\"Accuracy: {accuracy(y_pred, y_test, threshold=0.5) * 100}%\")"
      ],
      "metadata": {
        "id": "INp0ymXcqaUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Going further: Make it clean, make it re-usable\n",
        "\n",
        "Now that we have defined the building blocks of any simple feed-forward multilayered neural network, let's pack it up into a nice Object Oriented code, using Python classes."
      ],
      "metadata": {
        "id": "5a3JPXtWq0fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The `Layer` class\n",
        "\n",
        "A `Layer` applies one step of operation (like the linear transform or the activation function) on data of shape `(n_samples, n_features)`.\n",
        "\n",
        "It can also store some parameters (like $\\mathbf{w}$ and $\\mathbf{b}$), and compute its own gradient with regard to its parameters or to some inputs.\n",
        "\n",
        "### A note on Python classes\n",
        "\n",
        "They work exactly like C# classes. You can declare attributes and methods, create abstract classes, etc.\n",
        "\n",
        "A class constructor is always called `__init__`. It can accepts any kind of parameters. It is not mandatory to declare it (if you have no parameters to pass at construction of the instance, you can always create objects by calling the class like this: `Layer()`.).\n",
        "\n",
        "All methods (including `__init__`) must take as first parameter `self`. `self` behaves exactly like `this` in C#, but is mandatory within a class in Python as soon as you use an attribute or a method of the class.\n",
        "\n",
        "Inheritance from a class is declared with `class B(A)`, which means that class `B` inherits from class `A`."
      ],
      "metadata": {
        "id": "zWUdfiyVrU8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base abstract class\n",
        "class Layer:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        # Will store all data that enters the layer\n",
        "        # (necessary to compute the gradient)\n",
        "        self.inputs = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, x, dL):\n",
        "        \"\"\"Backward pass (backpropagation)\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def update(self, lr):\n",
        "        \"\"\"Parameter update (gradient descent), if any. Else, just pass.\"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "HzQ-L_VIqipR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense layer\n",
        "\n",
        "This layer defines weights and biases between neurons and applies a linear transform.\n",
        "\n",
        "Its two main methods (`forward` and `backward`) implements both forward an backward path in a composable way: They can be chained to any other layer.\n",
        "\n",
        "####Â Forward pass\n",
        "\n",
        "`forward` method implements the following mechanism, for any layer $l$ in the network:\n",
        "\n",
        "$$\\mathbf{z}^{(l)} = \\mathbf{x}^{(l-1)} \\cdot \\mathbf{W}^{(l)} + \\mathbf{b}^{(l)}$$\n",
        "\n",
        "where $\\mathbf{x}^{(l-1)}$ are the previous layer $l-1$ outputs (or the network inputs $\\mathbf{x}$ if $l$ is the first layer).\n",
        "\n",
        "Hence, `dense2.forward(dense1.forward(dense0.forward(x)))` would yield the output of a 3-layers perceptron (without activation function).\n",
        "\n",
        "In the following code, we will refer to $\\mathbf{x}^{(l-1)}$ using the `x` parameter in the `forward` function, meaning any kind of input entering the layer (from a previous layer or not).\n",
        "\n",
        "#### Backward pass\n",
        "\n",
        "Similarly, we can compute gradients in a composable way using the `backward` method.\n",
        "\n",
        "You may already have noticed that the more layers we add, the more we repeat the same operations during backpropagation. Let's consider we do not have any activation function for now in our network (adding them won't add to much complexity though):\n",
        "\n",
        "- Gradient with regard to parameters of layer $n$ (top layer):\n",
        "\n",
        "$$\\nabla_\\mathbf{w_n} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{w_n}}$$\n",
        "\n",
        "$$\\nabla_\\mathbf{b_n} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{b_n}}$$\n",
        "\n",
        "- Gradient with regard to inputs of layer $n$ (top layer), which are $z_{n-1}$, the outputs of layer $n-1$:\n",
        "\n",
        "$$\\nabla_\\mathbf{z_{n-1}} (\\mathcal{L}) = \\frac{\\partial\\mathcal{L}}{\\partial \\mathbf{y}} \\cdot \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{z_{n-1}}}$$\n",
        "\n",
        "We can therefore express gradient with regard to parameters of layer $n-1$ (one layer before) as:\n",
        "\n",
        "$$\\nabla_\\mathbf{w_{n-1}} (\\mathcal{L}) = \\nabla_\\mathbf{z_{n-1}} (\\mathcal{L}) \\cdot \\frac{\\partial \\mathbf{z_{n-1}}}{\\partial \\mathbf{w_{n-1}}} $$\n",
        "\n",
        "$$\\nabla_\\mathbf{b_{n-1}} (\\mathcal{L}) = \\nabla_\\mathbf{z_{n-1}} (\\mathcal{L}) \\cdot \\frac{\\partial \\mathbf{z_{n-1}}}{\\partial \\mathbf{b_{n-1}}} $$\n",
        "\n",
        "In fact, we just need every layer $n-1$ `backward` function to take as parameter the previously computed gradient $\\nabla_\\mathbf{z_{n-1}} (\\mathcal{L})$, to store the gradients it needs for the update step ($\\nabla_\\mathbf{w_{n-1}} (\\mathcal{L})$ and $\\nabla_\\mathbf{b_{n-1}} (\\mathcal{L})$) and to return the gradient for the next layer $n-2$, $\\nabla_\\mathbf{z_{n-2}} (\\mathcal{L})$.\n",
        "\n",
        "Hence, `dense0.backward(dense1.backward(dense2.backward(d_loss)))` would yield the gradients of a 3-layers perceptron (without activation function), given the loss gradient `d_loss` (notice how the order of the layer is inverted compared to the `forward` function).\n",
        "\n",
        "In the next code, we will refer to $\\nabla_\\mathbf{z_{n-1}} (\\mathcal{L})$ using the `dL` parameter of the backward function (roughly meaning \"the derivative of error coming from the loss and layers above\")."
      ],
      "metadata": {
        "id": "qT0OMFEstyz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(Layer):\n",
        "\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        super().__init__()  # call parent class constructor\n",
        "        # Now, self.inputs exists.\n",
        "\n",
        "        self.w, self.b = create_layer(input_shape, output_shape)\n",
        "\n",
        "        #Â gradients will be stored here between backward and update\n",
        "        self.grad_w = None\n",
        "        self.grad_b = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = ...\n",
        "        self.inputs = x  # store inputs for gradient computation\n",
        "        return h\n",
        "\n",
        "    def backward(self, dL):\n",
        "\n",
        "        # compute all possible gradients\n",
        "        grad_z_w = d_linear(self.inputs, self.w, self.b, with_regard_to=\"w\")\n",
        "        grad_z_b = d_linear(self.inputs, self.w, self.b, with_regard_to=\"b\")\n",
        "        grad_z_x = d_linear(self.inputs, self.w, self.b, with_regard_to=\"x\")\n",
        "\n",
        "        #Â store gradients needed for update\n",
        "        self.grad_w = ...\n",
        "        self.grad_b = ...\n",
        "\n",
        "        # return error gradient for propagation to previous layers\n",
        "        return np.dot(dL, grad_z_x)\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.w = ...\n",
        "        self.b = ..."
      ],
      "metadata": {
        "id": "UynyTz5Qtw5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sigmoid and Tanh layers\n",
        "\n",
        "These layers apply some activation function of data.\n",
        "\n",
        "We define their `forward` and `backward` function is a similar way as for the `Dense` layer. `forward` applies the function on any inputs `x` (for instance, outputs from a previous layer). `backward` computes gradients with regard to the inputs of the function and the previously accumulated gradient `dL`. This is overall the exact same operations as in the training loop defined earlier."
      ],
      "metadata": {
        "id": "5mSZ2kWJu29f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh(Layer):\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "    def backward(self, dL):\n",
        "        ..."
      ],
      "metadata": {
        "id": "z43iR7AsuoeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(Layer):\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "    def backward(self, dL):\n",
        "        ..."
      ],
      "metadata": {
        "id": "yrhAo9Yiweif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The `Model` class\n",
        "\n",
        "This class will hold all layers in one place, and perform the full forward,backward, and update steps.\n",
        "\n",
        "Now that we have defined our layers in a way that we can compose them, let's create a final class that will hold everything together. The forward pass of a `Model` is now just the succession of foward operations of all layers in that `Model`, from first layer to last, given some input data.\n",
        "\n",
        "Similarly, the backward pass is the succession of backward operations of all layers from last to first, given some loss gradient.\n",
        "\n",
        "Both computations can be performed within simple for-loops iterating over the layers list:\n",
        "\n",
        "```python\n",
        "# Forward pass of whole model\n",
        "for layer in layers:\n",
        "    y = layer(x)\n",
        "    x = y  # pass output to next layer\n",
        "```\n",
        "\n",
        "```python\n",
        "# Backward pass of whole model\n",
        "\n",
        "#Â reverse layers now, to go from top to bottom layers!\n",
        "for layer in reversed(layers):\n",
        "    dL_next = layer(dL)\n",
        "    dL = dL_next  # pass gradient to previous layer\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-kfxZ3Fqw1GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Call all layers one after the other,\n",
        "        # from bottom layers to top layers.\n",
        "        ...\n",
        "\n",
        "        return y\n",
        "\n",
        "    def backward(self, dL):\n",
        "\n",
        "        # Pass gradient from top layers to bottom layers.\n",
        "        for layer in reversed(self.layers): # reverse layer order\n",
        "            ...\n",
        "\n",
        "    def update(self, lr):\n",
        "\n",
        "        for layer in self.layers:\n",
        "            layer.update(lr)"
      ],
      "metadata": {
        "id": "5EtX-NZ7xGQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â Create a n layer perceptron (2 to begin with)\n",
        "model = ..."
      ],
      "metadata": {
        "id": "p9CLPBLX2sBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with the model object\n",
        "n_epochs = 100\n",
        "lr = 0.01\n",
        "loss_values = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = ...\n",
        "\n",
        "    # Loss\n",
        "    loss = ...\n",
        "    loss_values.append(loss)\n",
        "\n",
        "    #Â Loss gradient\n",
        "    dL = ...\n",
        "\n",
        "    #Â Backward pass\n",
        "    ...\n",
        "\n",
        "    # Parameters update\n",
        "    ..."
      ],
      "metadata": {
        "id": "I4hRsjI321W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_values)\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")"
      ],
      "metadata": {
        "id": "758aM0HY42ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.linspace(-2.5, 2.5, 100)\n",
        "x2 = np.linspace(-1.5, 1.5, 100)\n",
        "\n",
        "X_grid = np.meshgrid(x1, x2)\n",
        "X_grid = np.concatenate([X_grid[0].reshape(-1, 1), X_grid[1].reshape(-1, 1)], axis=1)\n",
        "\n",
        "# Calling the whole network is much easier now!\n",
        "y_pred = model.forward(X_grid)\n",
        "\n",
        "y_pred = y_pred.reshape(100, 100)\n",
        "\n",
        "plt.contourf(*np.meshgrid(x1, x2), y_pred, cmap=\"coolwarm\")\n",
        "plt.colorbar(label=\"Sigmoid activation value\")\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
        "plt.xlabel(\"Feature #0\")\n",
        "plt.ylabel(\"Feature #1\")\n",
        "plt.title(\"Output neuron activation for all data plane\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0hDV1GoWYvGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â Apply model forward method to make predictions on test data\n",
        "y_pred = ...\n",
        "print(f\"Accuracy: {accuracy(y_pred, y_test, threshold=0.5) * 100}%\")"
      ],
      "metadata": {
        "id": "gANgiW2jkddA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question (bonus): Apply your `Model` on more complex datasets (like we did in other TDs).\n",
        "\n",
        "For instance, go back to the Titanic or Fashion-MNIST datasets and try you own tools on it (you may need to create new activation functions like softmax and new losses! cf. Crossentropy section)\n",
        "\n",
        "###Â Question (bonus): Make a visualization of what is happening in the first layer of your two layered perceptron (maybe we can look at the loss landscape for a couple parameters only ?) Try to spot the local minima."
      ],
      "metadata": {
        "id": "V4vmsb45kuya"
      }
    }
  ]
}